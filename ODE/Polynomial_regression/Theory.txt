OVERVIEW:
Polynomial Regression is an extension of linear regression used to model the relationship between an independent variable (x) and a dependent variable (y) when the relationship is non-linear. Instead of fitting a straight line, polynomial regression fits a curve by using polynomial terms of x.It is commonly used when data shows curvature and cannot be accurately represented by a straight line.The general form of a polynomial regression equation is:
y = a₀ + a₁x + a₂x² + a₃x³ + … + aₙxⁿ
where
a₀, a₁, a₂, …, aₙ are regression coefficients
n is the degree of the polynomial

MATHEMATICAL FOUNDATION:
Polynomial regression is based on the Least Squares Method, where the sum of squared differences between observed and predicted values is minimized.
Error for each data point:
ei = yi − ŷi

ALGORITHM STEPS:
1.Read number of data points (n)
2.Read degree of polynomial (d)
3.Read n pairs of x and y values
4.Generate polynomial terms: x, x², x³, …, xᵈ
5.Construct normal equations using least squares method
6.Form matrix equations AX = B
7.Solve the system using Gaussian elimination or matrix inversion
8.Obtain coefficients a₀, a₁, a₂, …, aₙ
9.Display polynomial regression equation

CONVERGENCE:
Produces a unique solution if matrix is non-singular
Accuracy increases with appropriate degree selection
Overfitting may occur for very high-degree polynomials

STOPPING CONDITION:
Single computation method
Terminates after solving the system of equations

ADVANTAGES:
Can model non-linear relationships
Flexible curve fitting
Simple extension of linear regression
Widely used in data analysis and prediction
Does not require non-linear optimization

DISADVANTAGES:
Sensitive to outliers
Overfitting for high-degree polynomials
Poor extrapolation outside data range
Increased computational complexity
Requires careful degree selection